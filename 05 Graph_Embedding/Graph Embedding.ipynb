{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e940df89",
   "metadata": {},
   "source": [
    "## üîÅ Graph Representation Learning\n",
    "\n",
    "### ‚ùì What is Graph Representation Learning?\n",
    "\n",
    "In modern semi-supervised learning, **graph representation learning** (also called **graph embedding**) refers to learning **efficient and independent features** from graph nodes, with the aim of using them in machine learning tasks such as prediction.\n",
    "\n",
    "---\n",
    "\n",
    "### üìå How It Works:\n",
    "\n",
    "Each node `u` in the graph is mapped to a **low-dimensional vector** (embedding):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fd2e1d",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"images/image1.png\" alt=\"Image\" width=\"600\"/>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24b5fa2",
   "metadata": {},
   "source": [
    "$$\n",
    "f: u \\to \\mathbb{R}^d\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5688c1",
   "metadata": {},
   "source": [
    "\n",
    "This resulting vector is known as the **embedding vector**.\n",
    "\n",
    "\n",
    "### üéØ Goal:\n",
    "\n",
    "The goal of these methods is to **embed nodes** into **low-dimensional vectors** in a way that **preserves their structural context** in the graph.  \n",
    "In other words, we want to **embed nodes into a hidden space** where the **geometric relationships** reflect the **original graph neighborhood structure**.\n",
    "\n",
    "\n",
    "### üß† Applications:\n",
    "\n",
    "- Node classification  \n",
    "- Link prediction  \n",
    "- Graph classification  \n",
    "- Anomaly detection  \n",
    "- Community detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fb179e",
   "metadata": {},
   "source": [
    "## üìä Graph Embedding\n",
    "\n",
    "Graph embedding is a technique that can address the challenge of graph analysis in a **cost-effective** and **precise** manner.  \n",
    "This method converts the graph into a **vector-based representation** (typically in lower dimensions) based on its structure.\n",
    "\n",
    "\n",
    "\n",
    "### üñºÔ∏è Visual Explanation of Graph Embedding Types\n",
    "\n",
    "**(A)** Original Graph  \n",
    "Nodes are color-coded into three clusters:\n",
    "- Blue: A, B, C, D  \n",
    "- Yellow: E, F, G  \n",
    "- Red: H, I, J  \n",
    "\n",
    "\n",
    "\n",
    "**(B)** Node Embedding  \n",
    "Each **node** is embedded into a 2D space, preserving structural similarity.  \n",
    "Nodes from the same cluster are located close to each other.\n",
    "\n",
    "\n",
    "\n",
    "**(C)** Edge Embedding  \n",
    "Each **edge** is mapped to a point in 2D space.  \n",
    "The goal is to preserve the edge-level relationships.\n",
    "\n",
    "\n",
    "\n",
    "**(D)** Subgraph Embedding  \n",
    "Groups of nodes (subgraphs) are represented in a compact form, capturing local structures like communities.\n",
    "\n",
    "\n",
    "\n",
    "**(E)** Whole Graph Embedding  \n",
    "The entire graph is embedded into a single point in space ‚Äî useful for comparing whole graphs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba8134a",
   "metadata": {},
   "source": [
    "# How can we learn the embedding function *f*?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae72a441",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"images/image2.png\" alt=\"Image\" width=\"600\"/>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7039fb",
   "metadata": {},
   "source": [
    "## üî∑ Node Embedding: Encoding with Matrix Formulation\n",
    "\n",
    "We focus on **node embedding** based on the **encoder-decoder framework**.\n",
    "\n",
    "### ‚úÖ Encoder Function\n",
    "\n",
    "We define a function that maps each node $v \\in \\mathcal{V}$ to an embedding vector $\\mathbf{z}_v \\in \\mathbb{R}^d$:\n",
    "\n",
    "$\\text{ENC} : \\mathcal{V} \\rightarrow \\mathbb{R}^d,\\quad \\text{ENC}(v) = \\mathbf{z}_v$\n",
    "\n",
    "This function **encodes** the node $v$ into a low-dimensional vector representation.\n",
    "\n",
    "\n",
    "\n",
    "### üü® Embedding Matrix $Z$\n",
    "\n",
    "We can arrange all node embeddings in a matrix:\n",
    "\n",
    "$Z \\in \\mathbb{R}^{d \\times |\\mathcal{V}|}$\n",
    "\n",
    "Each **column** of $Z$ corresponds to the embedding of one node:\n",
    "\n",
    "$Z[:, v] = \\mathbf{z}_v$\n",
    "\n",
    "So we can write:\n",
    "\n",
    "$\\text{ENC}(v) = Z \\cdot \\mathbf{x}_v$\n",
    "\n",
    "where $\\mathbf{x}_v$ is a **one-hot vector** indicating the index of node $v$.\n",
    "\n",
    "\n",
    "\n",
    "### üìå Notes:\n",
    "\n",
    "- Each **column** of $Z$ represents the **embedding** for a node.\n",
    "- $\\mathbf{z}_v \\in \\mathbb{R}^d$: the latent representation of node $v$.\n",
    "- This formulation allows us to apply vector operations efficiently.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d73577c",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"images/image3.png\" alt=\"Image\" width=\"600\"/>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cebbc6d",
   "metadata": {},
   "source": [
    "### üéØ Decoder Objective: Reconstructing the Relationship Between Nodes $u$ and $v$\n",
    "\n",
    "In graph representation learning, the **decoder** reconstructs information about the original graph using the node embeddings:\n",
    "\n",
    "$$\n",
    "\\text{DEC}: \\mathbb{R}^d \\times \\mathbb{R}^d \\rightarrow \\mathbb{R}^+\n",
    "$$\n",
    "\n",
    "The decoder receives the embeddings of nodes $u$ and $v$, and estimates their similarity:\n",
    "\n",
    "$$\n",
    "\\text{DEC}(\\text{ENC}(u), \\text{ENC}(v)) = \\text{DEC}(z_u, z_v) \\approx S[u, v]\n",
    "$$\n",
    "\n",
    "- Here, $S[u, v]$ is an entry in the **similarity matrix** $S$, which captures how similar or connected nodes $u$ and $v$ are in the original graph.\n",
    "\n",
    "\n",
    "\n",
    "### üí° A Simple Choice for $S$:\n",
    "\n",
    "We can use the adjacency matrix $A$ of the graph as the similarity matrix:\n",
    "\n",
    "$$\n",
    "S[u, v] \\triangleq A[u, v]\n",
    "$$\n",
    "\n",
    "This means:\n",
    "\n",
    "- $S[u, v] = 1$ if nodes $u$ and $v$ are connected  \n",
    "- $S[u, v] = 0$ otherwise\n",
    "\n",
    "### üîπ Common Neighbors\n",
    "\n",
    "To calculate the number of common neighbors between nodes $v_i$ and $v_j$, we can compute:\n",
    "\n",
    "$$\n",
    "S_{CN} = AA\n",
    "$$\n",
    "\n",
    "- For an **undirected graph**, the matrix $S_{CN}[i][j]$ shows the number of common neighbors between nodes $v_i$ and $v_j$.\n",
    "\n",
    "- For a **directed graph**, $S_{CN}[i][j]$ counts the number of nodes $v_k$ such that there are **paths from $v_j$ to $v_k$ and from $v_k$ to $v_i$** ‚Äî i.e., $v_j \\rightarrow v_k \\rightarrow v_i$.\n",
    "\n",
    "\n",
    "### üîÑ Pairwise Decoder\n",
    "\n",
    "A **pairwise decoder** $\\text{DEC}(z_u, z_v)$ predicts the **relationship or similarity** between nodes $u$ and $v$.  \n",
    "For example, it may estimate whether the two nodes are **neighbors** in the original graph.\n",
    "\n",
    "\n",
    "\n",
    "> ‚úÖ The goal is to **minimize reconstruction error** between the predicted similarity and the true similarity in $S$,  \n",
    "> thus optimizing both the **encoder** and the **decoder** functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7944bd89",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1c0e2a",
   "metadata": {},
   "source": [
    "# üî∑ Node Representation Learning: Shallow Embedding\n",
    "\n",
    "- This is an **unsupervised** method for node representation learning.\n",
    "\n",
    "- We **do not use node labels**.\n",
    "- We **do not use node features**.\n",
    "\n",
    "- The goal is to **directly estimate an embedding vector for each node**, such that certain aspects of the graph structure are preserved.\n",
    "\n",
    "- These embeddings are **independent of any downstream prediction task**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cc4646",
   "metadata": {},
   "source": [
    "## Shallow Embedding\n",
    "\n",
    "- $z_u$: the embedding of node $u$, which is the target of our learning process.\n",
    "\n",
    "- If $\\mathcal{D}$ is the set of training data pairs, the goal is to minimize the following loss function $\\mathcal{L}$:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\sum_{(u,v) \\in \\mathcal{D}} \\ell\\left( \\text{DEC}(z_u, z_v),\\ \\text{S}[u,v] \\right)\n",
    "$$\n",
    "\n",
    "where $\\ell: \\mathbb{R} \\times \\mathbb{R} \\rightarrow \\mathbb{R}$\n",
    "\n",
    "- $\\ell$ is a loss function that measures the difference between the decoded similarity $\\text{DEC}(z_u, z_v)$ and the true similarity $S[u,v]$.\n",
    "\n",
    "- The loss function $\\ell$ can vary depending on how similarity and the decoder are defined. A common choice is the **mean squared error** for regression or classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7603be01",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a263fca",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab792ca7",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3367b45",
   "metadata": {},
   "source": [
    "# Creating Node Representations with DeepWalk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a7b5c9",
   "metadata": {},
   "source": [
    "\n",
    "# üìå Introducing Word2Vec\n",
    "\n",
    "The first step to comprehending the DeepWalk algorithm is to understand its major component: **Word2Vec**.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† What is Word2Vec?\n",
    "\n",
    "Word2Vec is one of the most influential deep-learning techniques in NLP.  \n",
    "Published in 2013 by **Tomas Mikolov et al.** at Google, it introduced a way to convert words into vectors ‚Äî called **embeddings** ‚Äî using large text datasets.\n",
    "\n",
    "These embeddings:\n",
    "\n",
    "- Allow computers to understand the **meaning of words** numerically.\n",
    "- Are useful in downstream tasks (like sentiment analysis or graph node classification).\n",
    "- Are a famous and patented example of successful ML architecture.\n",
    "\n",
    "\n",
    "## üìä Example Embeddings\n",
    "\n",
    "Here are a few example word vectors:\n",
    "\n",
    "```\n",
    "vec(king)   = [‚àí2.1, 4.1, 0.6]  \n",
    "vec(queen)  = [‚àí1.9, 2.6, 1.5]  \n",
    "vec(man)    = [3.0, ‚àí1.1, ‚àí2.0]  \n",
    "vec(woman)  = [2.8, ‚àí2.6, ‚àí1.1]\n",
    "```\n",
    "\n",
    "These are simplified 3-dimensional representations, but real embeddings are often 100‚Äì300 dimensions.\n",
    "\n",
    "\n",
    "## üßÆ Similarity by Euclidean Distance\n",
    "\n",
    "Let‚Äôs compare the Euclidean distances between words:\n",
    "\n",
    "- Distance between **king** and **queen**: $4.37$\n",
    "- Distance between **king** and **woman**: $8.47$\n",
    "\n",
    "This tells us:\n",
    "\n",
    "‚û° $vec(king)$ is **closer** to $vec(queen)$ than it is to $vec(woman)$.\n",
    "\n",
    "\n",
    "\n",
    "## üîÅ Cosine Similarity (Angle-Based Comparison)\n",
    "\n",
    "Instead of using distances, **cosine similarity** is often used.  \n",
    "It compares **angles**, not magnitudes ‚Äî which makes it better when lengths differ.\n",
    "\n",
    "It is defined as:\n",
    "\n",
    "$$\n",
    "\\text{cosine\\_similarity}(\\vec{A}, \\vec{B}) = \\cos(\\theta) = \\frac{\\vec{A} \\cdot \\vec{B}}{\\|\\vec{A}\\| \\cdot \\|\\vec{B}\\|}\n",
    "$$\n",
    "\n",
    "- $\\vec{A} \\cdot \\vec{B}$ = dot product  \n",
    "- $\\|\\vec{A}\\|$ = length (norm) of vector A\n",
    "\n",
    "\n",
    "\n",
    "## üí° Vector Arithmetic: Word Analogies\n",
    "\n",
    "One surprising ability of Word2Vec is solving analogies using simple vector math.\n",
    "\n",
    "Famous example:\n",
    "\n",
    "> \"**man** is to **woman** as **king** is to ___?\"\n",
    "\n",
    "This is calculated as:\n",
    "\n",
    "$$\n",
    "\\vec{king} - \\vec{man} + \\vec{woman} \\approx \\vec{queen}\n",
    "$$\n",
    "\n",
    "This relationship doesn‚Äôt always hold exactly, but it works surprisingly well in many cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f98c84e",
   "metadata": {},
   "source": [
    "# CBOW vs Skip-gram (Word2Vec)\n",
    "\n",
    "## üß† Core Concept\n",
    "Both **CBOW** and **Skip-gram** are models used in Word2Vec to learn word embeddings ‚Äî dense vector representations of words ‚Äî based on their context in a sentence.\n",
    "\n",
    "---\n",
    "\n",
    "## üìò CBOW (Continuous Bag-of-Words)\n",
    "This is trained to predict a word using its\n",
    "surrounding context (words coming before and after the target word). The order of context\n",
    "words does not matter since their embeddings are summed in the model. The authors claim to\n",
    "obtain better results using four words before and after the one that is predicted.\n",
    "\n",
    "### ‚úÖ Goal:\n",
    "Predict the **center word** given its **context words**.\n",
    "\n",
    "### üìå Example:\n",
    "For the sentence:  \n",
    "`The cat sits on the mat`\n",
    "\n",
    "CBOW input and output would be:  \n",
    "**Input (Context):** `The, cat, on, the`  \n",
    "**Output (Target):** `sits`\n",
    "\n",
    "\n",
    "## üìó Skip-gram\n",
    "Here, we feed a single word to the model and try to predict\n",
    "the words around it. Increasing the range of context words leads to better embeddings but also\n",
    "increases the training time.\n",
    "\n",
    "\n",
    "### ‚úÖ Goal:\n",
    "Predict the **context words** given the **center word**.\n",
    "\n",
    "### üìå Example:\n",
    "For the sentence:  \n",
    "`The cat sits on the mat`\n",
    "\n",
    "Skip-gram input and output would be:  \n",
    "**Input (Center):** `sits`  \n",
    "**Output (Context):** `The, cat, on, the`\n",
    "\n",
    "<center>\n",
    "    <img src=\"images/image4.jpg\" alt=\"Image\" width=\"600\"/>\n",
    "</center>\n",
    "\n",
    "\n",
    "## üìä Comparison Table\n",
    "\n",
    "| Feature         | CBOW                          | Skip-gram                        |\n",
    "|----------------|-------------------------------|----------------------------------|\n",
    "| Input           | Context words                 | Center word                      |\n",
    "| Output          | Center word                   | Context words                    |\n",
    "| Speed           | Faster to train               | Slower but more accurate         |\n",
    "| Good for        | Frequent words                | Rare words                       |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e614d731",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25458154",
   "metadata": {},
   "source": [
    "\n",
    "## üìå Creating Skip-grams\n",
    "\n",
    "For now, we will focus on the **skip-gram model** since it is the architecture used by **DeepWalk**.\n",
    "\n",
    "Skip-grams are implemented as **pairs of words** with the following structure:\n",
    "\n",
    "```\n",
    "(target word, context word)\n",
    "```\n",
    "\n",
    "- `target word`: the input word to the model.\n",
    "- `context word`: the word the model tries to predict (surrounding words).\n",
    "\n",
    "\n",
    "\n",
    "### üîß Parameter: `context size`\n",
    "\n",
    "The number of skip-gram pairs generated for a given target word depends on a parameter called **context size**, which defines how many words before and after the target word are considered context.\n",
    "\n",
    "\n",
    "\n",
    "### üìä Example \n",
    "\n",
    "Let‚Äôs take the sentence:  \n",
    "**\"the train was late\"**\n",
    "\n",
    "<center>\n",
    "    <img src=\"images/image5.jpg\" alt=\"Image\" width=\"600\"/>\n",
    "</center>\n",
    "\n",
    "### üß† Practical Usage\n",
    "\n",
    "- The same idea applies to a **corpus** of text, not just a single sentence.\n",
    "- We **store all context words** for the same target word in a **list** to save memory.\n",
    "- The next example will apply this to an entire paragraph, using:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e7e7af",
   "metadata": {},
   "source": [
    "### In the following example, we create skip-grams for an entire paragraph stored in the text variable. We set the CONTEXT_SIZE variable to 2, which means we will look at the two words before and after our target word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e0e8ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec5f5494",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63b461ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "\n",
    "text = \"\"\"\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc eu sem \n",
    "scelerisque, dictum eros aliquam, accumsan quam. Pellentesque tempus, lorem ut \n",
    "semper fermentum, ante turpis accumsan ex, sit amet ultricies tortor erat quis \n",
    "nulla. Nunc consectetur ligula sit amet purus porttitor, vel tempus tortor \n",
    "scelerisque. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices \n",
    "posuere cubilia curae; Quisque suscipit ligula nec faucibus accumsan. Duis \n",
    "vulputate massa sit amet viverra hendrerit. Integer maximus quis sapien id \n",
    "convallis. Donec elementum placerat ex laoreet gravida. Praesent quis enim \n",
    "facilisis, bibendum est nec, pharetra ex. Etiam pharetra congue justo, eget \n",
    "imperdiet diam varius non. Mauris dolor lectus, interdum in laoreet quis, \n",
    "faucibus vitae velit. Donec lacinia dui eget maximus cursus. Class aptent taciti\n",
    "sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Vivamus\n",
    "tincidunt velit eget nisi ornare convallis. Pellentesque habitant morbi \n",
    "tristique senectus et netus et malesuada fames ac turpis egestas. Donec \n",
    "tristique ultrices tortor at accumsan.\n",
    "\"\"\".split()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64fec29",
   "metadata": {},
   "source": [
    "Next, we create the skip-grams thanks to a simple for loop to consider every word in text.\n",
    "A list comprehension generates the context words, stored in the skipgrams list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f99a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create skipgrams\n",
    "skipgrams = []\n",
    "for i in range(CONTEXT_SIZE, len(text) - CONTEXT_SIZE):\n",
    "    array = [text[j] for j in np.arange(i - CONTEXT_SIZE, i + CONTEXT_SIZE + 1) if j != i]\n",
    "    skipgrams.append((text[i], array))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf5c0b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dolor', ['Lorem', 'ipsum', 'sit', 'amet,']), ('sit', ['ipsum', 'dolor', 'amet,', 'consectetur'])]\n"
     ]
    }
   ],
   "source": [
    "print(skipgrams[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6d1346",
   "metadata": {},
   "source": [
    "These two target words, with their corresponding context, work to show what the inputs to Word2Vec\n",
    "look like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7095f5e1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
