{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPc3Iv4xhtx6ky62owq6sHL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjmousavi97/Graph-Neural-Networks/blob/main/09_Graph_classification/src/graph_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zxLsSikvS72",
        "outputId": "c373c69b-062b-492e-93dc-9368164d691d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.loader import DataLoader"
      ],
      "metadata": {
        "id": "ASXS5Yi0IZ_Y"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TUDataset(root='.', name='PROTEINS').shuffle()"
      ],
      "metadata": {
        "id": "kyiVa0flIp7Q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"dataset: {dataset}\")\n",
        "print(f\"Number of Graphs: {len(dataset)}\")\n",
        "print(f\"Number of Nodes: {dataset[0].num_nodes}\")\n",
        "print(f\"Number of Features: {dataset.num_features}\")\n",
        "print(f\"Number of Classes: {dataset.num_classes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVj9kuPGI3X3",
        "outputId": "c829217b-3765-4a70-97dd-e3dc006c590d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset: PROTEINS(1113)\n",
            "Number of Graphs: 1113\n",
            "Number of Nodes: 18\n",
            "Number of Features: 3\n",
            "Number of Classes: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset[:int(len(dataset) * 0.8)]\n",
        "val_dataset = dataset[int(len(dataset) * 0.8):int(len(dataset) * 0.9)]\n",
        "test_dataset = dataset[int(len(dataset) * 0.9):]\n",
        "\n",
        "print(f\"Number of training graphs: {len(train_dataset)}\")\n",
        "print(f\"Number of validation graphs: {len(val_dataset)}\")\n",
        "print(f\"Number of test graphs: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfA0Py9YJczu",
        "outputId": "16387c2e-da59-482c-c1ec-d71c6f1889d9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training graphs: 890\n",
            "Number of validation graphs: 111\n",
            "Number of test graphs: 112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "print(\"\\nTrain Loader:\")\n",
        "for i, batch in enumerate(train_loader):\n",
        "    print(f\" - batch{i+1}: {batch}\")\n",
        "\n",
        "print(\"\\nValidation Loader:\")\n",
        "for i, batch in enumerate(val_loader):\n",
        "    print(f\" - batch{i+1}: {batch}\")\n",
        "\n",
        "print(\"\\nTest Loader\")\n",
        "for i, batch in enumerate(test_loader):\n",
        "    print(f\" - batch{i+1}: {batch}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zn1kg_W_JnWW",
        "outputId": "1bb21ca5-45de-4e31-a87e-efc603f54bc0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Loader:\n",
            " - batch1: DataBatch(edge_index=[2, 7758], x=[2182, 3], y=[64], batch=[2182], ptr=[65])\n",
            " - batch2: DataBatch(edge_index=[2, 8004], x=[2157, 3], y=[64], batch=[2157], ptr=[65])\n",
            " - batch3: DataBatch(edge_index=[2, 11238], x=[2989, 3], y=[64], batch=[2989], ptr=[65])\n",
            " - batch4: DataBatch(edge_index=[2, 8630], x=[2348, 3], y=[64], batch=[2348], ptr=[65])\n",
            " - batch5: DataBatch(edge_index=[2, 10772], x=[2845, 3], y=[64], batch=[2845], ptr=[65])\n",
            " - batch6: DataBatch(edge_index=[2, 9946], x=[2620, 3], y=[64], batch=[2620], ptr=[65])\n",
            " - batch7: DataBatch(edge_index=[2, 9348], x=[2501, 3], y=[64], batch=[2501], ptr=[65])\n",
            " - batch8: DataBatch(edge_index=[2, 9620], x=[2637, 3], y=[64], batch=[2637], ptr=[65])\n",
            " - batch9: DataBatch(edge_index=[2, 8704], x=[2412, 3], y=[64], batch=[2412], ptr=[65])\n",
            " - batch10: DataBatch(edge_index=[2, 9392], x=[2617, 3], y=[64], batch=[2617], ptr=[65])\n",
            " - batch11: DataBatch(edge_index=[2, 7568], x=[1981, 3], y=[64], batch=[1981], ptr=[65])\n",
            " - batch12: DataBatch(edge_index=[2, 9474], x=[2488, 3], y=[64], batch=[2488], ptr=[65])\n",
            " - batch13: DataBatch(edge_index=[2, 8258], x=[2228, 3], y=[64], batch=[2228], ptr=[65])\n",
            " - batch14: DataBatch(edge_index=[2, 7710], x=[1989, 3], y=[58], batch=[1989], ptr=[59])\n",
            "\n",
            "Validation Loader:\n",
            " - batch1: DataBatch(edge_index=[2, 8444], x=[2197, 3], y=[64], batch=[2197], ptr=[65])\n",
            " - batch2: DataBatch(edge_index=[2, 4662], x=[1267, 3], y=[47], batch=[1267], ptr=[48])\n",
            "\n",
            "Test Loader\n",
            " - batch1: DataBatch(edge_index=[2, 14400], x=[3907, 3], y=[64], batch=[3907], ptr=[65])\n",
            " - batch2: DataBatch(edge_index=[2, 8160], x=[2106, 3], y=[48], batch=[2106], ptr=[49])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ§  Summary: How GIN Works with Multiple Graphs (Batch Processing)\n",
        "\n",
        "- Each batch contains several graphs.  \n",
        "  Each graph has multiple nodes with feature vectors and its own edge structure.\n",
        "\n",
        "- PyTorch Geometric combines all graphs in the batch into **one big graph**:\n",
        "  - `x` â†’ all node features stacked together  \n",
        "  - `edge_index` â†’ edges of all graphs with shifted node indices  \n",
        "  - `batch` â†’ vector indicating which node belongs to which graph\n",
        "\n",
        "- A single **forward pass** is done for the entire batch (not one per graph).\n",
        "\n",
        "- Inside each GIN layer:\n",
        "$$\n",
        "h_v^{(k)} = \\mathrm{MLP}^{(k)}\\Big((1+\\epsilon)\\,h_v^{(k-1)} + \\mathrm{AGG}\\big(\\{h_u^{(k-1)} \\mid u \\in \\mathcal{N}(v)\\}\\big)\\Big)\n",
        "$$\n",
        "\n",
        "  - **MLP** = small neural network shared across all nodes and all graphs.  \n",
        "  - **AGG** = aggregation function (`add`, `mean`, or `max`).  \n",
        "  - **Îµ (eps)** controls the weight of the nodeâ€™s own features (can be learnable if `train_eps=True`).\n",
        "\n",
        "- ðŸ” **Weight sharing**:\n",
        "  - All nodes in all graphs share the same weights for each GIN layer.  \n",
        "  - Only node features (`x`) and graph structures (`edge_index`) differ.  \n",
        "  - During training, gradients from all graphs in the batch are averaged,  \n",
        "    and the shared weights are updated **once per batch**.\n",
        "\n",
        "- ðŸ§© After the GIN layers:\n",
        "  - Node embeddings are aggregated (via `global_add_pool`, `global_mean_pool`, etc.)  \n",
        "    to produce one embedding per graph.\n",
        "\n",
        "- âš™ï¸ Then a final classifier (usually an MLP) predicts the label for each graph.\n",
        "\n",
        "- âœ… Summary of updates:\n",
        "  | Level | Shared Weights? | Updated When? |\n",
        "  |--------|-----------------|----------------|\n",
        "  | Nodes within a graph | âœ… Yes | N/A |\n",
        "  | Graphs within a batch | âœ… Yes | Once per batch |\n",
        "  | Between batches | âœ… Continue from previous step | After each optimizer step |\n",
        "\n",
        "**In short:**  \n",
        "GIN learns a single message-passing function (the same weights) that applies to every node of every graph, combines messages from neighbors, and updates weights only once per batch using the averaged gradient of all graphs.\n"
      ],
      "metadata": {
        "id": "m1yMyi7MNe7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_geometric.nn import GINConv\n",
        "from torch_geometric.nn import global_add_pool"
      ],
      "metadata": {
        "id": "83DA4dKLon7Y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(pred_y, y):\n",
        "    return ((pred_y == y).sum() / len(y)).item()"
      ],
      "metadata": {
        "id": "uAW285Un9Pca"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GIN(nn.Module):\n",
        "    def __init__(self, dim_h):\n",
        "        super().__init__()\n",
        "\n",
        "        self.gin1 = GINConv(Sequential(Linear(dataset.num_features, dim_h),\n",
        "                                       BatchNorm1d(dim_h), ReLU(),\n",
        "                                       Linear(dim_h, dim_h), ReLU()))\n",
        "        self.gin2 = GINConv(Sequential(Linear(dim_h, dim_h),\n",
        "                                       BatchNorm1d(dim_h), ReLU(),\n",
        "                                       Linear(dim_h, dim_h), ReLU()))\n",
        "        self.gin3 = GINConv(Sequential(Linear(dim_h, dim_h),\n",
        "                                       BatchNorm1d(dim_h), ReLU(),\n",
        "                                       Linear(dim_h, dim_h), ReLU()))\n",
        "\n",
        "        self.lin1 = Linear(3 * dim_h, dim_h)\n",
        "        self.lin2 = Linear(dim_h, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x1 = self.gin1(x, edge_index)\n",
        "        x2 = self.gin2(x1, edge_index)\n",
        "        x3 = self.gin3(x2, edge_index)\n",
        "\n",
        "        h1 = global_add_pool(x1, batch)\n",
        "        h2 = global_add_pool(x2, batch)\n",
        "        h3 = global_add_pool(x3, batch)\n",
        "\n",
        "        h = torch.cat([h1, h2, h3], dim=1)\n",
        "        h = self.lin1(h).relu()\n",
        "        h = F.dropout(h, p=0.5, training=self.training)\n",
        "        h = self.lin2(h)\n",
        "\n",
        "        return h\n",
        "\n",
        "    def fit(self, train_loader, val_loader, epochs):\n",
        "        self.train()\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        total_loss_list, acc_list, val_loss_list, val_acc_list = [], [], [], []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            total_loss, acc, val_loss, val_acc = 0, 0, 0, 0\n",
        "\n",
        "            for data in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                out = self(data.x, data.edge_index, data.batch)\n",
        "                loss = criterion(out, data.y)\n",
        "                total_loss += loss.item() / len(train_loader)\n",
        "                acc += accuracy(out.argmax(dim=1), data.y) / len(train_loader)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for data in val_loader:\n",
        "                    out = self(data.x, data.edge_index, data.batch)\n",
        "                    val_loss += criterion(out, data.y).item() / len(val_loader)\n",
        "                    val_acc += accuracy(out.argmax(dim=1), data.y) / len(val_loader)\n",
        "\n",
        "            total_loss_list.append(total_loss)\n",
        "            acc_list.append(acc)\n",
        "            val_loss_list.append(val_loss)\n",
        "            val_acc_list.append(val_acc)\n",
        "\n",
        "            print(f'Epoch {epoch+1}/{epochs}, '\n",
        "                  f'Train Loss: {total_loss:.4f}, Train Acc: {acc:.4f}, '\n",
        "                  f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "        return total_loss_list, acc_list, val_loss_list, val_acc_list"
      ],
      "metadata": {
        "id": "cefYlLYXtkoV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import inspect\n",
        "# print(inspect.getsource(GINConv.forward))"
      ],
      "metadata": {
        "id": "GwJjhah4yU8Q",
        "outputId": "befdd56e-f952-4c90-eaf4-23acbabdafaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    def forward(\n",
            "        self,\n",
            "        x: Union[Tensor, OptPairTensor],\n",
            "        edge_index: Adj,\n",
            "        size: Size = None,\n",
            "    ) -> Tensor:\n",
            "\n",
            "        if isinstance(x, Tensor):\n",
            "            x = (x, x)\n",
            "\n",
            "        # propagate_type: (x: OptPairTensor)\n",
            "        out = self.propagate(edge_index, x=x, size=size)\n",
            "\n",
            "        x_r = x[1]\n",
            "        if x_r is not None:\n",
            "            out = out + (1 + self.eps) * x_r\n",
            "\n",
            "        return self.nn(out)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JChvPQx7zLG8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}